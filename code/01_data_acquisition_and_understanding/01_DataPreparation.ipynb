{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET FOLDER WHERE DATA WILL DBE DOWNLOADED\n",
    "base_folder = 'C:\\\\Users\\\\remoteuser\\\\Desktop\\\\Data\\\\Sentiment140_Classification'\n",
    "\n",
    "if not os.path.exists(base_folder):\n",
    "    os.makedirs(base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to download the sentiment140 dataset\n",
    "data_url='http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to download and process data\n",
    "\n",
    "def change_base_dir(base_dir_path):\n",
    "    \"\"\" Change the working directopry of the code\"\"\"\n",
    "    \n",
    "    if not os.path.exists(base_dir_path):\n",
    "        print ('creating directory', base_dir_path)\n",
    "        os.makedirs(base_dir_path)\n",
    "    print ('Changing base directory to ', base_dir_path)\n",
    "    os.chdir(base_dir_path)\n",
    "\n",
    "def download_data(download_url, filename='downloaded_data.zip'):\n",
    "    \"\"\" Download and extract data \"\"\"\n",
    "    \n",
    "    downloaded_filename = os.path.join('.', filename)\n",
    "    print ('Step 1: Downloading data')\n",
    "    urllib.request.urlretrieve(download_url,downloaded_filename)\n",
    "    print ('Step 2: Extracting data')\n",
    "    zipfile=ZipFile(downloaded_filename)\n",
    "    zipfile.extractall('./')\n",
    "    zipfile.close()\n",
    "\n",
    "def extract_tweets_and_labels(filename ):\n",
    "    \"\"\" Extract tweets and labels from the downloaded data\"\"\"\n",
    "    \n",
    "    print ('Step 3: Reading the data as a dataframe')\n",
    "    df=pd.read_csv(filename, header=None, encoding='iso-8859-1')    \n",
    "    df.columns=['Label','TweetId','Date','Query','User','Text']\n",
    "    print ('Read {} lines'.format(df.shape[0]))\n",
    "    print ('Discarding neutral tweets')\n",
    "    df=df[df.Label!=2]\n",
    "    print ('No of lines in the data after filtering neutral tweets: {}'.format(df.shape[0]))\n",
    "    print ('Step 4: Shuffling the data')\n",
    "    train_length=int(df.shape[0]*0.8)    \n",
    "    df=df.sample(frac=1) # reshuffling the data\n",
    "      \n",
    "    df['Text']=df['Text'].astype(str).apply(lambda x:x.strip())#.encode('ascii','ignore')#str.decode('utf8','ignore')#.str.encode('ascii','ignore')\n",
    "    print (df.head())\n",
    "    print ('Step 5: Dividing into test and train datasets')\n",
    "    df_train = df.iloc[:train_length, :]\n",
    "    df_test = df.iloc[train_length:, :]    \n",
    "    \n",
    "    print ('Step 6: Exporting the train and test datasets')    \n",
    "    print ('Exporting training data of rows {}'.format(df_train.shape[0]))\n",
    "    export_prefix='training'\n",
    "    df_train[['Label']].to_csv(export_prefix+'_label.csv', header=False, index=False)\n",
    "    df_train[['Text']].to_csv(export_prefix+'_text.csv', header=False, index=False)\n",
    "    print ('Target distribution in the training data is as follows')\n",
    "    print ('\\n',df_train['Label'].value_counts()) \n",
    "    \n",
    "    print ('Exporting training data of rows {}'.format(df_test.shape[0]))\n",
    "    export_prefix='testing'\n",
    "    df_test[['Label']].to_csv(export_prefix+'_label.csv', header=False, index=False)\n",
    "    df_test[['Text']].to_csv(export_prefix+'_text.csv', header=False, index=False)\n",
    "    print ('Target distribution in the testing data is as follows')\n",
    "    print ('\\n',df_test['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing base directory to  C:\\Users\\remoteuser\\Desktop\\Data\\Sentiment140_Classification\n",
      "Step 1: Downloading data\n",
      "Step 2: Extracting data\n",
      "Step 3: Reading the data as a dataframe\n",
      "Read 1600000 lines\n",
      "Discarding neutral tweets\n",
      "No of lines in the data after filtering neutral tweets: 1600000\n",
      "Step 4: Shuffling the data\n",
      "         Label     TweetId                          Date     Query  \\\n",
      "1402631      4  2054746685  Sat Jun 06 08:00:20 PDT 2009  NO_QUERY   \n",
      "526370       0  2194241833  Tue Jun 16 09:31:54 PDT 2009  NO_QUERY   \n",
      "930555       4  1760360995  Sun May 10 21:19:41 PDT 2009  NO_QUERY   \n",
      "1193636      4  1984310132  Sun May 31 14:51:21 PDT 2009  NO_QUERY   \n",
      "881404       4  1685807773  Sun May 03 02:11:07 PDT 2009  NO_QUERY   \n",
      "\n",
      "                User                                               Text  \n",
      "1402631      omgsean  Going to fort smith today. stoked for the rest...  \n",
      "526370        ad0815       Argh.. Omniture Discover 2 is annoying me...  \n",
      "930555   laurenlemon                    @colinloretz hah! Thanks Colin.  \n",
      "1193636    robotstar    Back from ambleside but am happy in my tummy...  \n",
      "881404    quinnifer_  @__parasite__ it can just eat the people we do...  \n",
      "Step 5: Dividing into test and train datasets\n",
      "Step 6: Exporting the train and test datasets\n",
      "Exporting training data of rows 1280000\n",
      "Target distribution in the training data is as follows\n",
      "\n",
      " 0    640152\n",
      "4    639848\n",
      "Name: Label, dtype: int64\n",
      "Exporting training data of rows 320000\n",
      "Target distribution in the testing data is as follows\n",
      "\n",
      " 4    160152\n",
      "0    159848\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Download and processing the data\n",
    "base_dir_path=base_folder\n",
    "change_base_dir(base_dir_path)\n",
    "download_data(data_url)\n",
    "extract_tweets_and_labels('training.1600000.processed.noemoticon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

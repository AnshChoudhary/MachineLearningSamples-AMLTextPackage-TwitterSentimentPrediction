{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn & Keras Text Classifier Pipeline with Word2Vec Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook shows how to train pipelines for word embeddigns and scikit classifier\n",
    "\n",
    "The pipeline takes as input a dataframe containing tweets in a text column, a word embedding file, and trains a scikit learn model. The modeling pipeline is then saved to a .zip file. This file can be loaded later and used for prediction and evaluation of new data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "working_dir = r\"C:\\\\Users\\\\remoteuser\\\\Desktop\\\\Data\\\\Sentiment140_Classification\"\n",
    "\n",
    "## Set training and test files\n",
    "training_tweet_filename = os.path.join(working_dir, 'training_text.csv')\n",
    "training_label_filename = os.path.join(working_dir, 'training_label.csv')\n",
    "test_tweet_filename = os.path.join(working_dir, 'testing_text.csv')\n",
    "test_label_filename = os.path.join(working_dir, 'testing_label.csv')\n",
    "\n",
    "## Set word2vec file, parameter file for model, and model pipeline file\n",
    "w2v_embeddings_filename = os.path.join(working_dir, 'w2vec.txt')\n",
    "params_file_path = os.path.join(working_dir, \"params.tsv\")\n",
    "sklearn_model_file = os.path.join(working_dir, 'sk_model.zip') \n",
    "keras_model_file = os.path.join(working_dir, 'keras_model.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azureml-tatk\n",
      "Version: 0.1.18123.2b3\n",
      "Summary: Microsoft Azure Machine Learning Package for Text Analytics\n",
      "Home-page: https://microsoft.sharepoint.com/teams/TextAnalyticsPackagePreview\n",
      "Author: Microsoft Corporation\n",
      "Author-email: amltap@microsoft.com\n",
      "License: UNKNOWN\n",
      "Location: c:\\users\\remoteuser\\appdata\\local\\amlworkbench\\python\\lib\\site-packages\n",
      "Requires: scipy, pandas, dill, gensim, qgrid, sklearn-crfsuite, pyspark, numpy, pdfminer.six, azure-ml-api-sdk, scikit-learn, lxml, azure-storage, h5py, ipython, nose, requests, keras, matplotlib, validators, unidecode, bqplot, jsonpickle, ipywidgets, ruamel.yaml, pytest, nltk, docker\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "from tatk.feature_extraction.word2vec_vectorizer import Word2VecVectorizer\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import tatk\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  \n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import num2words\n",
    "\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tatk.pipelines.text_classification.text_classifier import TextClassifier\n",
    "from tatk.pipelines.text_classification.keras_text_classifier import KerasTextClassifier\n",
    "from tatk.feature_extraction.callable_vectorizer import CallableVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "!pip show azureml-tatk\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data loading the preprocessing functions for tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "# In the following code, we replace Emails, URLS, emoticons etc with special labels\n",
    "pos_emoticons=[\"(^.^)\",\"(^-^)\",\"(^_^)\",\"(^_~)\",\"(^3^)\",\"(^o^)\",\"(~_^)\",\"*)\",\":)\",\":*\",\":-*\",\":]\",\":^)\",\":}\",\n",
    "               \":>\",\":3\",\":b\",\":-b\",\":c)\",\":D\",\":-D\",\":O\",\":-O\",\":o)\",\":p\",\":-p\",\":P\",\":-P\",\":Þ\",\":-Þ\",\":X\",\n",
    "               \":-X\",\";)\",\";-)\",\";]\",\";D\",\"^)\",\"^.~\",\"_)m\",\" ~.^\",\"<=8\",\"<3\",\"<333\",\"=)\",\"=///=\",\"=]\",\"=^_^=\",\n",
    "               \"=<_<=\",\"=>.<=\",\" =>.>=\",\" =3\",\"=D\",\"=p\",\"0-0\",\"0w0\",\"8D\",\"8O\",\"B)\",\"C:\",\"d'-'\",\"d(>w<)b\",\":-)\",\n",
    "               \"d^_^b\",\"qB-)\",\"X3\",\"xD\",\"XD\",\"XP\",\"ʘ‿ʘ\",\"❤\",\"💜\",\"💚\",\"💕\",\"💙\",\"💛\",\"💓\",\"💝\",\"💖\",\"💞\",\n",
    "               \"💘\",\"💗\",\"😗\",\"😘\",\"😙\",\"😚\",\"😻\",\"😀\",\"😁\",\"😃\",\"☺\",\"😄\",\"😆\",\"😇\",\"😉\",\"😊\",\"😋\",\"😍\",\n",
    "               \"😎\",\"😏\",\"😛\",\"😜\",\"😝\",\"😮\",\"😸\",\"😹\",\"😺\",\"😻\",\"😼\",\"👍\"]\n",
    "\n",
    "neg_emoticons=[\"--!--\",\"(,_,)\",\"(-.-)\",\"(._.)\",\"(;.;)9\",\"(>.<)\",\"(>_<)\",\"(>_>)\",\"(¬_¬)\",\"(X_X)\",\":&\",\":(\",\":'(\",\n",
    "               \":-(\",\":-/\",\":-@[1]\",\":[\",\":\\\\\",\":{\",\":<\",\":-9\",\":c\",\":S\",\";(\",\";*(\",\";_;\",\"^>_>^\",\"^o)\",\"_|_\",\n",
    "               \"`_´\",\"</3\",\"<=3\",\"=/\",\"=\\\\\",\">:(\",\">:-(\",\"💔\",\"☹️\",\"😌\",\"😒\",\"😓\",\"😔\",\"😕\",\"😖\",\"😞\",\"😟\",\n",
    "               \"😠\",\"😡\",\"😢\",\"😣\",\"😤\",\"😥\",\"😦\",\"😧\",\"😨\",\"😩\",\"😪\",\"😫\",\"😬\",\"😭\",\"😯\",\"😰\",\"😱\",\"😲\",\n",
    "               \"😳\",\"😴\",\"😷\",\"😾\",\"😿\",\"🙀\",\"💀\",\"👎\"]\n",
    "\n",
    "emoticonsDict = {}\n",
    "for i,each in enumerate(pos_emoticons):\n",
    "    emoticonsDict[each]=' POS_EMOTICON_'+num2words.num2words(i).upper()+' '\n",
    "    \n",
    "for i,each in enumerate(neg_emoticons):\n",
    "    emoticonsDict[each]=' NEG_EMOTICON_'+num2words.num2words(i).upper()+' '\n",
    "    \n",
    "# use these three lines to do the replacement\n",
    "rep = dict((re.escape(k), v) for k, v in emoticonsDict.items())\n",
    "emoticonsPattern = re.compile(\"|\".join(rep.keys()))\n",
    "\n",
    "# Read in files\n",
    "def read_tweets(filename):\n",
    "    \"\"\"Read the raw tweet data from a file. Replace Emails etc with special tokens \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        all_lines=f.readlines()\n",
    "        padded_lines=[]\n",
    "        for line in all_lines:\n",
    "            line = emoticonsPattern.sub(lambda m: rep[re.escape(m.group(0))], line.lower().strip())\n",
    "            line=re.sub(r'(.)\\1{2,}', r'\\1\\1',line)\n",
    "            words_tokens=[token for token in TweetTokenizer().tokenize(line)]                    \n",
    "            line= ' '.join(token for token in words_tokens )         \n",
    "            padded_lines.append(line)\n",
    "    return padded_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in tweet training data and training labels, and combine into one data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going to fort smith today . stoked for the res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argh .. omniture discover 2 is annoying me ..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@colinloretz hah ! thanks colin .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          raw_tweets  labels\n",
       "0  going to fort smith today . stoked for the res...       1\n",
       "1      argh .. omniture discover 2 is annoying me ..       0\n",
       "2                  @colinloretz hah ! thanks colin .       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Read in tweet file. Labels are 4 and 0 (4 being positive and 0 being negative)\n",
    "tweets = read_tweets(training_tweet_filename)\n",
    "\n",
    "with open(training_label_filename, 'r') as f:\n",
    "    all_lines=f.readlines()\n",
    "    tweet_labels = []\n",
    "    for line in all_lines:\n",
    "        line = line.strip()\n",
    "        label = 0\n",
    "        if line == '4':\n",
    "            label = 1\n",
    "        #else:\n",
    "        #    label = 'negative'\n",
    "        tweet_labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({'raw_tweets':tweets, 'labels':tweet_labels}, columns=['raw_tweets','labels'])\n",
    "display(df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    640152\n",
       "1    639848\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count the labels in training set\n",
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CallableVectorizer to pre-process tweets in a given dataframe\n",
    "#### This takes raw tweets and further processes them to generate processed tweets which are used to run training / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallableVectorizer::tatk_fit_transform ==> start\n",
      "CallableVectorizer::tatk_fit_transform ==> end \t Time taken: 0.1 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_tweets</th>\n",
       "      <th>labels</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going to fort smith today . stoked for the res...</td>\n",
       "      <td>1</td>\n",
       "      <td>going to fort smith today . stoked for the res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argh .. omniture discover 2 is annoying me ..</td>\n",
       "      <td>0</td>\n",
       "      <td>argh .. omniture discover 2 is annoying me ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@colinloretz hah ! thanks colin .</td>\n",
       "      <td>1</td>\n",
       "      <td>AT colinloretz hah ! thanks colin .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          raw_tweets  labels  \\\n",
       "0  going to fort smith today . stoked for the res...       1   \n",
       "1      argh .. omniture discover 2 is annoying me ..       0   \n",
       "2                  @colinloretz hah ! thanks colin .       1   \n",
       "\n",
       "                                              tweets  \n",
       "0  going to fort smith today . stoked for the res...  \n",
       "1      argh .. omniture discover 2 is annoying me ..  \n",
       "2                AT colinloretz hah ! thanks colin .  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions wihch are to be used to pre-process tweets\n",
    "def to_lower_case(x):\n",
    "    return x.lower()\n",
    "\n",
    "def emailsReplace(x):\n",
    "    return x.replace(r'[\\w\\.-]+@[\\w\\.-]+', ' EMAIL ')\n",
    "\n",
    "def numsReplace(x):\n",
    "    return x.replace(r'[\\w\\.-]+@[\\w\\.-]+', ' NUM ')\n",
    "\n",
    "def userMentionsReplace(x):\n",
    "    return x.replace(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)', ' USER ')\n",
    "\n",
    "def urlReplace(x):\n",
    "    return x.replace(r'r(f|ht)(tp)(s?)(://)(.*)[.|/][^ ]+', ' URL ')\n",
    "\n",
    "def punctuationReplace(x):\n",
    "    return x.replace(r'(?<=\\w)[^\\s\\w](?![^\\s\\w])', ' PUN ')\n",
    "\n",
    "def atReplace(x):\n",
    "    return x.replace(r'@', ' AT ')\n",
    "\n",
    "# Chain functions into a list\n",
    "featFuncs=[to_lower_case, emailsReplace, numsReplace, userMentionsReplace, urlReplace, punctuationReplace, atReplace]\n",
    "\n",
    "# Create a transformer specifying functions, \n",
    "callable = CallableVectorizer(input_col=\"raw_tweets\", output_col=\"tweets\", feat_list=featFuncs, preprocessor = True)\n",
    "processed_df = callable.tatk_fit_transform(df)\n",
    "\n",
    "processed_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going to fort smith today . stoked for the res...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argh .. omniture discover 2 is annoying me ..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT colinloretz hah ! thanks colin .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  labels\n",
       "0  going to fort smith today . stoked for the res...       1\n",
       "1      argh .. omniture discover 2 is annoying me ..       0\n",
       "2                AT colinloretz hah ! thanks colin .       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df[['tweets','labels']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_tweets</th>\n",
       "      <th>labels</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186081</th>\n",
       "      <td>\" @glamorousvandal sure come within 10 days , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  AT glamorousvandal sure come within 10 days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970629</th>\n",
       "      <td>is listening to my music now as i cant stand h...</td>\n",
       "      <td>1</td>\n",
       "      <td>is listening to my music now as i cant stand h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640576</th>\n",
       "      <td>totally nothing</td>\n",
       "      <td>0</td>\n",
       "      <td>totally nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                raw_tweets  labels  \\\n",
       "1186081  \" @glamorousvandal sure come within 10 days , ...       0   \n",
       "970629   is listening to my music now as i cant stand h...       1   \n",
       "640576                                     totally nothing       0   \n",
       "\n",
       "                                                    tweets  \n",
       "1186081  \"  AT glamorousvandal sure come within 10 days...  \n",
       "970629   is listening to my music now as i cant stand h...  \n",
       "640576                                     totally nothing  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = train_test_split(df, test_size=0.33)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit learn text classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define scikit learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier::create_pipeline ==> start\n",
      ":: number of jobs for the pipeline : 6\n",
      "0\ttweets_nltk_preprocessor\n",
      "1\ttweets_word2vec\n",
      "2\tassembler\n",
      "3\tlearner\n",
      "TextClassifier::create_pipeline ==> end\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "#params = {'tol': [0.0001, 0.001], 'max_iter': [5, 10]}\n",
    "\n",
    "## Define classifier from scikit learn\n",
    "log_reg_learner =  LogisticRegression(penalty='l2', dual=False, tol=0.0001, \n",
    "                            C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                            class_weight=None, random_state=None, \n",
    "                            solver='lbfgs', max_iter=10, \n",
    "                            verbose=1, warm_start=True, n_jobs=3) \n",
    "\n",
    "# Train the model on tweets\n",
    "text_classifier = TextClassifier(embedding_file_path = w2v_embeddings_filename,\n",
    "                                estimator=log_reg_learner, \n",
    "                                extract_word_ngrams=False,\n",
    "                                text_cols = [\"tweets\"], \n",
    "                                label_cols = [\"labels\"])\n",
    "\n",
    "## Export parameters of the model\n",
    "text_classifier.export_params(params_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit classifier on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier::fit ==> start\n",
      "schema: col=raw_tweets:TX:0 col=labels:I8:1 col=tweets:TX:2 header+\n",
      "NltkPreprocessor::tatk_fit_transform ==> start\n",
      "NltkPreprocessor::tatk_fit_transform ==> end \t Time taken: 0.32 mins\n",
      "Word2VecVectorizer::tatk_fit_transform ==> start\n",
      "Word2VecVectorizer::tatk_fit_transform ==> end \t Time taken: 1.42 mins\n",
      "VectorAssembler::transform ==> start, num of input records=857600\n",
      "(857600, 50)\n",
      "all_features::\n",
      "(857600, 50)\n",
      "Time taken: 0.01 mins\n",
      "VectorAssembler::transform ==> end\n",
      "LogisticRegression::tatk_fit ==> start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 out of   1 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression::tatk_fit ==> end \t Time taken: 0.17 mins\n",
      "Time taken: 1.92 mins\n",
      "TextClassifier::fit ==> end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextClassifier(add_index_col=False, callable_proprocessors_list=None,\n",
       "        cat_cols=None, char_hashing_original=False, col_prefix='tmp_00_',\n",
       "        decompose_n_grams=False, detect_phrases=False,\n",
       "        dictionary_categories=None, dictionary_file_path=None,\n",
       "        embedding_file_path='C:\\\\\\\\Users\\\\\\\\remoteuser\\\\\\\\Desktop\\\\\\\\Data\\\\\\\\Sentiment140_Classification\\\\w2vec.txt',\n",
       "        embedding_file_path_fastText=None, estimator=None,\n",
       "        estimator_vectorizers_list=None, extract_char_ngrams=False,\n",
       "        extract_word_ngrams=False, label_cols=['labels'],\n",
       "        numeric_cols=None, pos_tagger_vectorizer=False,\n",
       "        preprocessor_dictionary_file_path=None, regex_replcaement='',\n",
       "        replace_regex_pattern=None, scale_numeric_cols=False,\n",
       "        text_callable_list=None, text_cols=['tweets'],\n",
       "        text_regex_list=None, weight_col=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the scikit learn training pipleine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextModel::save ==> start\n",
      "TatkPipeline::save ==> start\n",
      "copy embedding file from  C:\\\\Users\\\\remoteuser\\\\Desktop\\\\Data\\\\Sentiment140_Classification\\w2vec.txt\n",
      "Time taken: 0.0 mins\n",
      "TatkPipeline::save ==> end\n",
      "Time taken: 0.06 mins\n",
      "BaseTextModel::save ==> end\n"
     ]
    }
   ],
   "source": [
    "text_classifier.save(sklearn_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and the training pipleine, predict and evaluate the accuracy on held-out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextModel::load ==> start\n",
      "TatkPipeline::load ==> start\n",
      "Word2VecVectorizer: Word2Vec model loaded from C:\\\\Users\\\\remoteuser\\\\Desktop\\\\Data\\\\Sentiment140_Classification\\sk_model.zip 2018-05-31 06.19.09\\sk_model\\pipeline\\tweets_word2vec\\embedding_table.txt\n",
      "Time taken: 0.06 mins\n",
      "TatkPipeline::load ==> end\n",
      "Time taken: 0.07 mins\n",
      "BaseTextModel::load ==> end\n"
     ]
    }
   ],
   "source": [
    "text_classifier_reloaded = TextClassifier.load(sklearn_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier ::predict ==> start\n",
      "NltkPreprocessor::tatk_transform ==> start\n",
      "NltkPreprocessor::tatk_transform ==> end \t Time taken: 0.16 mins\n",
      "Word2VecVectorizer::tatk_transform ==> start\n",
      "Word2VecVectorizer::tatk_transform ==> end \t Time taken: 0.7 mins\n",
      "VectorAssembler::transform ==> start, num of input records=422400\n",
      "(422400, 50)\n",
      "all_features::\n",
      "(422400, 50)\n",
      "Time taken: 0.01 mins\n",
      "VectorAssembler::transform ==> end\n",
      "LogisticRegression::tatk_predict_proba ==> start\n",
      "LogisticRegression::tatk_predict_proba ==> end \t Time taken: 0.03 mins\n",
      "LogisticRegression::tatk_predict ==> start\n",
      "LogisticRegression::tatk_predict ==> end \t Time taken: 0.03 mins\n",
      "Time taken: 0.93 mins\n",
      "TextClassifier ::predict ==> end\n",
      "Order of Labels in predicted probabilities saved to attribute label_order of the class object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518808</th>\n",
       "      <td>AT kt_93 hehe i know</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.27810977456126795, 0.721890225438732]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166749</th>\n",
       "      <td>AT katiecorless bollocks . i would of loved t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4726533465040218, 0.5273466534959782]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840126</th>\n",
       "      <td>AT porceleindoll come to wa and i'll help you...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.12090388768582727, 0.8790961123141727]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets  labels  \\\n",
       "518808                               AT kt_93 hehe i know       1   \n",
       "166749   AT katiecorless bollocks . i would of loved t...       0   \n",
       "840126   AT porceleindoll come to wa and i'll help you...       1   \n",
       "\n",
       "                                    probabilities  prediction  \n",
       "518808   [0.27810977456126795, 0.721890225438732]           1  \n",
       "166749   [0.4726533465040218, 0.5273466534959782]           1  \n",
       "840126  [0.12090388768582727, 0.8790961123141727]           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_df = text_classifier_reloaded.predict(valid)\n",
    "display(predicted_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier ::evaluate ==> start\n",
      "Time taken: 0.02 mins\n",
      "TextClassifier ::evaluate ==> end\n",
      "TextClassifier ::evaluate ==> start\n",
      "Time taken: 0.02 mins\n",
      "TextClassifier ::evaluate ==> end\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a44bac26a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7524928200298536"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier_reloaded.evaluate(valid)\n",
    "\n",
    "evaluations = text_classifier_reloaded.evaluate(valid)\n",
    "evaluations.plot_confusion_matrix(normalize=False,\n",
    "                                title='Confusion matrix, without normalization', \n",
    "                                print_confusion_matrix=False,\n",
    "                                figsize=(6,6),\n",
    "                                colors=None)\n",
    "evaluations.get_metrics('micro_avg_accuracy')\n",
    "evaluations.get_metrics('macro_avg_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keras classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasEmbeddingTextClassifier::create_pipeline ==> start\n",
      "Word2VecVectorizer::load_embeddings ==> start\n",
      "Time taken: 0.06 mins\n",
      "Word2VecVectorizer::load_embeddings ==> end\n",
      "num_words=69953\n",
      ":: number of jobs for the pipeline : 6\n",
      "0\tnltk_preprocessor\n",
      "1\tvectorizer\n",
      "2\tlearner\n",
      "KerasEmbeddingTextClassifier::create_pipeline ==> end\n"
     ]
    }
   ],
   "source": [
    "from tatk.pipelines.text_classification.keras_embedding_text_classifier import KerasEmbeddingTextClassifier\n",
    "keras_text_classifier = KerasEmbeddingTextClassifier(embedding_file_path=w2v_embeddings_filename, \n",
    "                                                     input_col=\"tweets\", \n",
    "                                                     label_cols=\"labels\",\n",
    "                                                     model_type=\"CNN\",\n",
    "                                                     binary_format=False, \n",
    "                                                     callbacks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 250,\n",
       " 'callbacks_list': ['tensorboard', 'checkpoint', 'early'],\n",
       " 'cuda_devices': '0',\n",
       " 'feature_cols': ['features'],\n",
       " 'input_padding_value': 69952,\n",
       " 'label_cols': ['labels'],\n",
       " 'log_path': 'C:\\\\Users\\\\remoteuser\\\\tatk\\\\resources\\\\logs',\n",
       " 'max_len': None,\n",
       " 'model__class_type': 'single-label',\n",
       " 'model__dropout_rate': 0.5,\n",
       " 'model__hidden_dims': 100,\n",
       " 'model__init_wordvecs': array([[-1.03649604, -1.48352396, -1.07123899, ..., -0.95034897,\n",
       "         -0.069777  , -0.046452  ],\n",
       "        [ 0.082796  ,  0.90919   ,  0.30086401, ...,  0.24328201,\n",
       "         -0.70956302,  0.70759702],\n",
       "        [-0.845285  , -1.73459303, -1.39133   , ..., -0.99724901,\n",
       "          0.093811  , -0.59610701],\n",
       "        ...,\n",
       "        [ 0.116024  , -0.15468501, -0.126646  , ...,  0.12105   ,\n",
       "          0.037048  , -0.011772  ],\n",
       "        [ 0.00430944,  0.03613211, -0.04568701, ..., -0.01723733,\n",
       "         -0.16511534,  0.01022116],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " 'model__kernel_size': [3, 4, 5],\n",
       " 'model__num_filters': 25,\n",
       " 'model__trainable_embedding': False,\n",
       " 'model__wordvecs_shape': (69953, 50),\n",
       " 'model_fn': <function tatk.estimators.keras_model_functions.keras_CNN_text_classifier_fn.keras_CNN_text_classifier_fn(with_embedding_layer, model_params, n_labels, num_features=None, num_sent_features=0)>,\n",
       " 'model_type': 'CNN',\n",
       " 'n_epochs': 10,\n",
       " 'n_labels': None,\n",
       " 'prediction_col': 'prediction',\n",
       " 'probabilities_col': 'probabilities',\n",
       " 'validation_split': 0.2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", n_epochs = 10)\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", batch_size = 250)\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", validation_split = 0.2)\n",
    "\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", model__kernel_size=[3,4,5])\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", model__num_filters=25)\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", model__dropout_rate  = 0.5)\n",
    "keras_text_classifier.set_step_params_by_name(\"learner\", model__hidden_dims  = 100)\n",
    "\n",
    "keras_text_classifier.set_step_params_by_name(\"vectorizer\", get_from_path=False)\n",
    "\n",
    "# Get parameters\n",
    "keras_text_classifier.get_step_params_by_name(\"learner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Keras classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasEmbeddingTextClassifier::fit ==> start\n",
      "schema: col=raw_tweets:TX:0 col=labels:I8:1 col=tweets:TX:2 header+\n",
      "NltkPreprocessor::tatk_fit_transform ==> start\n",
      "NltkPreprocessor::tatk_fit_transform ==> end \t Time taken: 0.33 mins\n",
      "Word2VecVectorizer::tatk_fit_transform ==> start\n",
      "Word2VecVectorizer::tatk_fit_transform ==> end \t Time taken: 0.24 mins\n",
      "KerasEmbeddingTextClassifierLearner::tatk_fit ==> start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     3497650     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 25)     3775        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 25)     5025        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 25)     6275        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 25)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 25)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 25)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75)           0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 75)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          7600        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,520,527\n",
      "Trainable params: 22,877\n",
      "Non-trainable params: 3,497,650\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547/2745 [===============>..............] - ETA: 1:53:33 - loss: 1.2908 - acc: 0.48 - ETA: 39:14 - loss: 1.2557 - acc: 0.5147 - ETA: 24:24 - loss: 1.2313 - acc: 0.49 - ETA: 15:45 - loss: 1.1944 - acc: 0.49 - ETA: 11:40 - loss: 1.1339 - acc: 0.48 - ETA: 9:31 - loss: 1.0706 - acc: 0.4992 - ETA: 7:39 - loss: 1.0243 - acc: 0.508 - ETA: 6:40 - loss: 0.9792 - acc: 0.516 - ETA: 5:06 - loss: 0.9221 - acc: 0.525 - ETA: 4:37 - loss: 0.8991 - acc: 0.530 - ETA: 4:01 - loss: 0.8706 - acc: 0.538 - ETA: 4:04 - loss: 0.8610 - acc: 0.539 - ETA: 3:47 - loss: 0.8486 - acc: 0.542 - ETA: 3:37 - loss: 0.8404 - acc: 0.544 - ETA: 3:03 - loss: 0.8167 - acc: 0.552 - ETA: 3:14 - loss: 0.8152 - acc: 0.553 - ETA: 3:18 - loss: 0.8087 - acc: 0.555 - ETA: 3:06 - loss: 0.7993 - acc: 0.558 - ETA: 3:10 - loss: 0.7931 - acc: 0.561 - ETA: 3:00 - loss: 0.7848 - acc: 0.564 - ETA: 2:57 - loss: 0.7819 - acc: 0.565 - ETA: 2:52 - loss: 0.7775 - acc: 0.568 - ETA: 2:52 - loss: 0.7709 - acc: 0.570 - ETA: 2:51 - loss: 0.7638 - acc: 0.574 - ETA: 2:46 - loss: 0.7546 - acc: 0.578 - ETA: 2:51 - loss: 0.7524 - acc: 0.579 - ETA: 2:46 - loss: 0.7482 - acc: 0.581 - ETA: 2:50 - loss: 0.7462 - acc: 0.582 - ETA: 2:46 - loss: 0.7383 - acc: 0.588 - ETA: 2:33 - loss: 0.7264 - acc: 0.595 - ETA: 2:23 - loss: 0.7202 - acc: 0.599 - ETA: 2:15 - loss: 0.7139 - acc: 0.603 - ETA: 2:08 - loss: 0.7082 - acc: 0.607 - ETA: 2:06 - loss: 0.7022 - acc: 0.611 - ETA: 2:07 - loss: 0.6988 - acc: 0.614 - ETA: 2:11 - loss: 0.6973 - acc: 0.615 - ETA: 2:11 - loss: 0.6968 - acc: 0.615 - ETA: 2:03 - loss: 0.6900 - acc: 0.620 - ETA: 2:02 - loss: 0.6856 - acc: 0.623 - ETA: 1:56 - loss: 0.6796 - acc: 0.627 - ETA: 1:58 - loss: 0.6782 - acc: 0.628 - ETA: 1:56 - loss: 0.6754 - acc: 0.630 - ETA: 1:59 - loss: 0.6748 - acc: 0.631 - ETA: 2:02 - loss: 0.6739 - acc: 0.632 - ETA: 1:57 - loss: 0.6691 - acc: 0.635 - ETA: 1:51 - loss: 0.6649 - acc: 0.638 - ETA: 1:47 - loss: 0.6610 - acc: 0.641 - ETA: 1:43 - loss: 0.6570 - acc: 0.644 - ETA: 1:39 - loss: 0.6529 - acc: 0.647 - ETA: 1:35 - loss: 0.6489 - acc: 0.650 - ETA: 1:32 - loss: 0.6448 - acc: 0.653 - ETA: 1:30 - loss: 0.6418 - acc: 0.656 - ETA: 1:29 - loss: 0.6407 - acc: 0.656 - ETA: 1:27 - loss: 0.6381 - acc: 0.658 - ETA: 1:26 - loss: 0.6362 - acc: 0.660 - ETA: 1:23 - loss: 0.6336 - acc: 0.662 - ETA: 1:24 - loss: 0.6327 - acc: 0.662 - ETA: 1:26 - loss: 0.6324 - acc: 0.663 - ETA: 1:24 - loss: 0.6295 - acc: 0.665 - ETA: 1:21 - loss: 0.6272 - acc: 0.667 - ETA: 1:19 - loss: 0.6245 - acc: 0.668 - ETA: 1:16 - loss: 0.6221 - acc: 0.670 - ETA: 1:14 - loss: 0.6194 - acc: 0.672 - ETA: 1:12 - loss: 0.6175 - acc: 0.674 - ETA: 1:12 - loss: 0.6167 - acc: 0.674 - ETA: 1:14 - loss: 0.6162 - acc: 0.675 - ETA: 1:15 - loss: 0.6160 - acc: 0.675 - ETA: 1:15 - loss: 0.6144 - acc: 0.676 - ETA: 1:13 - loss: 0.6121 - acc: 0.678 - ETA: 1:12 - loss: 0.6104 - acc: 0.679 - ETA: 1:10 - loss: 0.6091 - acc: 0.680 - ETA: 1:09 - loss: 0.6077 - acc: 0.681 - ETA: 1:07 - loss: 0.6061 - acc: 0.682 - ETA: 1:06 - loss: 0.6044 - acc: 0.683 - ETA: 1:06 - loss: 0.6042 - acc: 0.684 - ETA: 1:06 - loss: 0.6041 - acc: 0.684 - ETA: 1:07 - loss: 0.6033 - acc: 0.684 - ETA: 1:07 - loss: 0.6024 - acc: 0.685 - ETA: 1:05 - loss: 0.6011 - acc: 0.686 - ETA: 1:05 - loss: 0.6001 - acc: 0.686 - ETA: 1:03 - loss: 0.5985 - acc: 0.688 - ETA: 1:02 - loss: 0.5970 - acc: 0.689 - ETA: 1:03 - loss: 0.5964 - acc: 0.689 - ETA: 1:02 - loss: 0.5948 - acc: 0.690 - ETA: 1:01 - loss: 0.5934 - acc: 0.691 - ETA: 1:01 - loss: 0.5931 - acc: 0.692 - ETA: 1:00 - loss: 0.5916 - acc: 0.693 - ETA: 59s - loss: 0.5904 - acc: 0.694 - ETA: 58s - loss: 0.5892 - acc: 0.69 - ETA: 58s - loss: 0.5887 - acc: 0.69 - ETA: 57s - loss: 0.5875 - acc: 0.69 - ETA: 56s - loss: 0.5865 - acc: 0.69 - ETA: 55s - loss: 0.5851 - acc: 0.69 - ETA: 54s - loss: 0.5846 - acc: 0.69 - ETA: 55s - loss: 0.5839 - acc: 0.69 - ETA: 56s - loss: 0.5836 - acc: 0.69 - ETA: 55s - loss: 0.5822 - acc: 0.69 - ETA: 54s - loss: 0.5810 - acc: 0.70 - ETA: 53s - loss: 0.5799 - acc: 0.70 - ETA: 52s - loss: 0.5787 - acc: 0.70 - ETA: 52s - loss: 0.5784 - acc: 0.70 - ETA: 52s - loss: 0.5783 - acc: 0.70 - ETA: 51s - loss: 0.5772 - acc: 0.70 - ETA: 52s - loss: 0.5770 - acc: 0.70 - ETA: 53s - loss: 0.5768 - acc: 0.70 - ETA: 53s - loss: 0.5762 - acc: 0.70 - ETA: 52s - loss: 0.5754 - acc: 0.70 - ETA: 51s - loss: 0.5743 - acc: 0.70 - ETA: 52s - loss: 0.5741 - acc: 0.70 - ETA: 51s - loss: 0.5730 - acc: 0.70 - ETA: 50s - loss: 0.5720 - acc: 0.70 - ETA: 51s - loss: 0.5713 - acc: 0.70 - ETA: 50s - loss: 0.5702 - acc: 0.70 - ETA: 49s - loss: 0.5689 - acc: 0.70 - ETA: 48s - loss: 0.5679 - acc: 0.71 - ETA: 47s - loss: 0.5671 - acc: 0.71 - ETA: 48s - loss: 0.5670 - acc: 0.71 - ETA: 47s - loss: 0.5660 - acc: 0.71 - ETA: 47s - loss: 0.5651 - acc: 0.71 - ETA: 47s - loss: 0.5647 - acc: 0.71 - ETA: 46s - loss: 0.5640 - acc: 0.71 - ETA: 46s - loss: 0.5633 - acc: 0.71 - ETA: 45s - loss: 0.5626 - acc: 0.71 - ETA: 44s - loss: 0.5619 - acc: 0.71 - ETA: 44s - loss: 0.5613 - acc: 0.71 - ETA: 44s - loss: 0.5612 - acc: 0.71 - ETA: 44s - loss: 0.5606 - acc: 0.71 - ETA: 43s - loss: 0.5598 - acc: 0.71 - ETA: 44s - loss: 0.5596 - acc: 0.71 - ETA: 43s - loss: 0.5589 - acc: 0.71 - ETA: 42s - loss: 0.5582 - acc: 0.71 - ETA: 43s - loss: 0.5578 - acc: 0.71 - ETA: 42s - loss: 0.5570 - acc: 0.71 - ETA: 42s - loss: 0.5561 - acc: 0.71 - ETA: 41s - loss: 0.5554 - acc: 0.71 - ETA: 41s - loss: 0.5544 - acc: 0.71 - ETA: 41s - loss: 0.5542 - acc: 0.71 - ETA: 41s - loss: 0.5541 - acc: 0.71 - ETA: 40s - loss: 0.5533 - acc: 0.72 - ETA: 40s - loss: 0.5525 - acc: 0.72 - ETA: 39s - loss: 0.5522 - acc: 0.72 - ETA: 38s - loss: 0.5516 - acc: 0.72 - ETA: 38s - loss: 0.5509 - acc: 0.72 - ETA: 37s - loss: 0.5504 - acc: 0.72 - ETA: 38s - loss: 0.5501 - acc: 0.72 - ETA: 38s - loss: 0.5498 - acc: 0.72 - ETA: 38s - loss: 0.5493 - acc: 0.72 - ETA: 37s - loss: 0.5485 - acc: 0.72 - ETA: 38s - loss: 0.5484 - acc: 0.72 - ETA: 37s - loss: 0.5478 - acc: 0.72 - ETA: 37s - loss: 0.5475 - acc: 0.72 - ETA: 36s - loss: 0.5469 - acc: 0.72 - ETA: 36s - loss: 0.5463 - acc: 0.72 - ETA: 36s - loss: 0.5457 - acc: 0.72 - ETA: 36s - loss: 0.5456 - acc: 0.72 - ETA: 36s - loss: 0.5454 - acc: 0.72 - ETA: 36s - loss: 0.5450 - acc: 0.72 - ETA: 35s - loss: 0.5447 - acc: 0.72 - ETA: 36s - loss: 0.5446 - acc: 0.72 - ETA: 35s - loss: 0.5442 - acc: 0.72 - ETA: 35s - loss: 0.5438 - acc: 0.72 - ETA: 35s - loss: 0.5435 - acc: 0.72 - ETA: 35s - loss: 0.5431 - acc: 0.72 - ETA: 34s - loss: 0.5429 - acc: 0.72 - ETA: 34s - loss: 0.5424 - acc: 0.72 - ETA: 34s - loss: 0.5418 - acc: 0.72 - ETA: 33s - loss: 0.5411 - acc: 0.72 - ETA: 33s - loss: 0.5405 - acc: 0.72 - ETA: 32s - loss: 0.5401 - acc: 0.72 - ETA: 32s - loss: 0.5396 - acc: 0.72 - ETA: 31s - loss: 0.5391 - acc: 0.72 - ETA: 31s - loss: 0.5390 - acc: 0.72 - ETA: 31s - loss: 0.5385 - acc: 0.73 - ETA: 30s - loss: 0.5381 - acc: 0.73 - ETA: 30s - loss: 0.5376 - acc: 0.73 - ETA: 30s - loss: 0.5371 - acc: 0.73 - ETA: 29s - loss: 0.5366 - acc: 0.73 - ETA: 30s - loss: 0.5365 - acc: 0.73 - ETA: 29s - loss: 0.5359 - acc: 0.73 - ETA: 29s - loss: 0.5354 - acc: 0.73 - ETA: 29s - loss: 0.5350 - acc: 0.73 - ETA: 28s - loss: 0.5345 - acc: 0.73 - ETA: 28s - loss: 0.5342 - acc: 0.73 - ETA: 28s - loss: 0.5337 - acc: 0.73 - ETA: 28s - loss: 0.5335 - acc: 0.73 - ETA: 28s - loss: 0.5331 - acc: 0.73 - ETA: 27s - loss: 0.5329 - acc: 0.73 - ETA: 27s - loss: 0.5324 - acc: 0.73 - ETA: 26s - loss: 0.5320 - acc: 0.73 - ETA: 26s - loss: 0.5317 - acc: 0.73 - ETA: 26s - loss: 0.5313 - acc: 0.73 - ETA: 25s - loss: 0.5309 - acc: 0.73 - ETA: 25s - loss: 0.5308 - acc: 0.73 - ETA: 25s - loss: 0.5303 - acc: 0.73 - ETA: 25s - loss: 0.5299 - acc: 0.73 - ETA: 24s - loss: 0.5294 - acc: 0.73 - ETA: 24s - loss: 0.5290 - acc: 0.73 - ETA: 24s - loss: 0.5287 - acc: 0.73 - ETA: 24s - loss: 0.5287 - acc: 0.73 - ETA: 23s - loss: 0.5284 - acc: 0.73 - ETA: 23s - loss: 0.5283 - acc: 0.73 - ETA: 23s - loss: 0.5278 - acc: 0.73 - ETA: 23s - loss: 0.5275 - acc: 0.73 - ETA: 23s - loss: 0.5275 - acc: 0.73 - ETA: 23s - loss: 0.5274 - acc: 0.73 - ETA: 23s - loss: 0.5270 - acc: 0.73 - ETA: 22s - loss: 0.5268 - acc: 0.73 - ETA: 22s - loss: 0.5265 - acc: 0.73 - ETA: 22s - loss: 0.5262 - acc: 0.73 - ETA: 22s - loss: 0.5260 - acc: 0.73892741/2745 [============================>.] - ETA: 21s - loss: 0.5258 - acc: 0.73 - ETA: 21s - loss: 0.5256 - acc: 0.73 - ETA: 21s - loss: 0.5256 - acc: 0.73 - ETA: 21s - loss: 0.5253 - acc: 0.73 - ETA: 21s - loss: 0.5253 - acc: 0.73 - ETA: 21s - loss: 0.5251 - acc: 0.73 - ETA: 21s - loss: 0.5248 - acc: 0.73 - ETA: 20s - loss: 0.5243 - acc: 0.74 - ETA: 20s - loss: 0.5238 - acc: 0.74 - ETA: 20s - loss: 0.5235 - acc: 0.74 - ETA: 20s - loss: 0.5232 - acc: 0.74 - ETA: 19s - loss: 0.5230 - acc: 0.74 - ETA: 19s - loss: 0.5226 - acc: 0.74 - ETA: 19s - loss: 0.5223 - acc: 0.74 - ETA: 19s - loss: 0.5220 - acc: 0.74 - ETA: 18s - loss: 0.5217 - acc: 0.74 - ETA: 18s - loss: 0.5214 - acc: 0.74 - ETA: 18s - loss: 0.5211 - acc: 0.74 - ETA: 17s - loss: 0.5207 - acc: 0.74 - ETA: 17s - loss: 0.5205 - acc: 0.74 - ETA: 17s - loss: 0.5202 - acc: 0.74 - ETA: 17s - loss: 0.5200 - acc: 0.74 - ETA: 17s - loss: 0.5197 - acc: 0.74 - ETA: 16s - loss: 0.5196 - acc: 0.74 - ETA: 16s - loss: 0.5192 - acc: 0.74 - ETA: 16s - loss: 0.5190 - acc: 0.74 - ETA: 16s - loss: 0.5187 - acc: 0.74 - ETA: 15s - loss: 0.5184 - acc: 0.74 - ETA: 15s - loss: 0.5181 - acc: 0.74 - ETA: 15s - loss: 0.5178 - acc: 0.74 - ETA: 15s - loss: 0.5176 - acc: 0.74 - ETA: 14s - loss: 0.5173 - acc: 0.74 - ETA: 14s - loss: 0.5169 - acc: 0.74 - ETA: 14s - loss: 0.5166 - acc: 0.74 - ETA: 14s - loss: 0.5163 - acc: 0.74 - ETA: 14s - loss: 0.5162 - acc: 0.74 - ETA: 13s - loss: 0.5159 - acc: 0.74 - ETA: 13s - loss: 0.5158 - acc: 0.74 - ETA: 13s - loss: 0.5155 - acc: 0.74 - ETA: 13s - loss: 0.5152 - acc: 0.74 - ETA: 13s - loss: 0.5150 - acc: 0.74 - ETA: 12s - loss: 0.5148 - acc: 0.74 - ETA: 12s - loss: 0.5145 - acc: 0.74 - ETA: 12s - loss: 0.5143 - acc: 0.74 - ETA: 12s - loss: 0.5139 - acc: 0.74 - ETA: 12s - loss: 0.5138 - acc: 0.74 - ETA: 11s - loss: 0.5135 - acc: 0.74 - ETA: 11s - loss: 0.5132 - acc: 0.74 - ETA: 11s - loss: 0.5129 - acc: 0.74 - ETA: 11s - loss: 0.5126 - acc: 0.74 - ETA: 11s - loss: 0.5125 - acc: 0.74 - ETA: 10s - loss: 0.5123 - acc: 0.74 - ETA: 10s - loss: 0.5121 - acc: 0.74 - ETA: 10s - loss: 0.5118 - acc: 0.74 - ETA: 10s - loss: 0.5116 - acc: 0.74 - ETA: 10s - loss: 0.5114 - acc: 0.74 - ETA: 9s - loss: 0.5110 - acc: 0.7490 - ETA: 9s - loss: 0.5108 - acc: 0.749 - ETA: 9s - loss: 0.5106 - acc: 0.749 - ETA: 9s - loss: 0.5104 - acc: 0.749 - ETA: 9s - loss: 0.5102 - acc: 0.749 - ETA: 8s - loss: 0.5100 - acc: 0.749 - ETA: 8s - loss: 0.5097 - acc: 0.749 - ETA: 8s - loss: 0.5095 - acc: 0.749 - ETA: 8s - loss: 0.5093 - acc: 0.750 - ETA: 8s - loss: 0.5091 - acc: 0.750 - ETA: 8s - loss: 0.5090 - acc: 0.750 - ETA: 7s - loss: 0.5088 - acc: 0.750 - ETA: 7s - loss: 0.5086 - acc: 0.750 - ETA: 7s - loss: 0.5084 - acc: 0.750 - ETA: 7s - loss: 0.5083 - acc: 0.750 - ETA: 7s - loss: 0.5080 - acc: 0.751 - ETA: 6s - loss: 0.5078 - acc: 0.751 - ETA: 6s - loss: 0.5076 - acc: 0.751 - ETA: 6s - loss: 0.5074 - acc: 0.751 - ETA: 6s - loss: 0.5071 - acc: 0.751 - ETA: 6s - loss: 0.5070 - acc: 0.751 - ETA: 6s - loss: 0.5068 - acc: 0.751 - ETA: 6s - loss: 0.5067 - acc: 0.751 - ETA: 5s - loss: 0.5066 - acc: 0.752 - ETA: 5s - loss: 0.5065 - acc: 0.752 - ETA: 5s - loss: 0.5064 - acc: 0.752 - ETA: 5s - loss: 0.5062 - acc: 0.752 - ETA: 5s - loss: 0.5060 - acc: 0.752 - ETA: 5s - loss: 0.5059 - acc: 0.752 - ETA: 5s - loss: 0.5056 - acc: 0.752 - ETA: 4s - loss: 0.5055 - acc: 0.752 - ETA: 4s - loss: 0.5052 - acc: 0.752 - ETA: 4s - loss: 0.5050 - acc: 0.753 - ETA: 4s - loss: 0.5048 - acc: 0.753 - ETA: 4s - loss: 0.5046 - acc: 0.753 - ETA: 4s - loss: 0.5044 - acc: 0.753 - ETA: 4s - loss: 0.5042 - acc: 0.753 - ETA: 3s - loss: 0.5040 - acc: 0.753 - ETA: 3s - loss: 0.5039 - acc: 0.753 - ETA: 3s - loss: 0.5036 - acc: 0.754 - ETA: 3s - loss: 0.5035 - acc: 0.754 - ETA: 3s - loss: 0.5033 - acc: 0.754 - ETA: 3s - loss: 0.5030 - acc: 0.754 - ETA: 2s - loss: 0.5029 - acc: 0.754 - ETA: 2s - loss: 0.5027 - acc: 0.754 - ETA: 2s - loss: 0.5026 - acc: 0.754 - ETA: 2s - loss: 0.5025 - acc: 0.754 - ETA: 2s - loss: 0.5023 - acc: 0.754 - ETA: 2s - loss: 0.5022 - acc: 0.754 - ETA: 2s - loss: 0.5019 - acc: 0.755 - ETA: 1s - loss: 0.5017 - acc: 0.755 - ETA: 1s - loss: 0.5015 - acc: 0.755 - ETA: 1s - loss: 0.5014 - acc: 0.755 - ETA: 1s - loss: 0.5012 - acc: 0.755 - ETA: 1s - loss: 0.5011 - acc: 0.755 - ETA: 1s - loss: 0.5009 - acc: 0.755 - ETA: 1s - loss: 0.5007 - acc: 0.756 - ETA: 0s - loss: 0.5005 - acc: 0.756 - ETA: 0s - loss: 0.5005 - acc: 0.756 - ETA: 0s - loss: 0.5004 - acc: 0.756 - ETA: 0s - loss: 0.5002 - acc: 0.756 - ETA: 0s - loss: 0.5001 - acc: 0.756 - ETA: 0s - loss: 0.5000 - acc: 0.756 - ETA: 0s - loss: 0.4999 - acc: 0.756 - ETA: 0s - loss: 0.4998 - acc: 0.756 - ETA: 0s - loss: 0.4998 - acc: 0.756 - ETA: 0s - loss: 0.4998 - acc: 0.756 - ETA: 0s - loss: 0.4998 - acc: 0.7566\n",
      "Epoch 00001: val_loss improved from inf to 0.47645, saving model to C:\\Users\\remoteuser\\tatk\\resources\\logs\\checkpoints\n",
      "2745/2745 [==============================] - 40s 15ms/step - loss: 0.4998 - acc: 0.7566 - val_loss: 0.4764 - val_acc: 0.7917\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2199/2745 [=======================>......] - ETA: 16s - loss: 0.4706 - acc: 0.77 - ETA: 13s - loss: 0.4439 - acc: 0.79 - ETA: 14s - loss: 0.4591 - acc: 0.78 - ETA: 13s - loss: 0.4584 - acc: 0.78 - ETA: 13s - loss: 0.4610 - acc: 0.78 - ETA: 13s - loss: 0.4571 - acc: 0.78 - ETA: 13s - loss: 0.4566 - acc: 0.78 - ETA: 13s - loss: 0.4569 - acc: 0.78 - ETA: 13s - loss: 0.4567 - acc: 0.78 - ETA: 13s - loss: 0.4564 - acc: 0.78 - ETA: 13s - loss: 0.4572 - acc: 0.78 - ETA: 13s - loss: 0.4571 - acc: 0.78 - ETA: 13s - loss: 0.4577 - acc: 0.78 - ETA: 13s - loss: 0.4585 - acc: 0.78 - ETA: 13s - loss: 0.4571 - acc: 0.78 - ETA: 13s - loss: 0.4563 - acc: 0.78 - ETA: 13s - loss: 0.4559 - acc: 0.78 - ETA: 13s - loss: 0.4565 - acc: 0.78 - ETA: 13s - loss: 0.4579 - acc: 0.78 - ETA: 13s - loss: 0.4584 - acc: 0.78 - ETA: 13s - loss: 0.4585 - acc: 0.78 - ETA: 13s - loss: 0.4589 - acc: 0.78 - ETA: 12s - loss: 0.4587 - acc: 0.78 - ETA: 12s - loss: 0.4583 - acc: 0.78 - ETA: 12s - loss: 0.4582 - acc: 0.78 - ETA: 12s - loss: 0.4584 - acc: 0.78 - ETA: 12s - loss: 0.4582 - acc: 0.78 - ETA: 12s - loss: 0.4589 - acc: 0.78 - ETA: 12s - loss: 0.4587 - acc: 0.78 - ETA: 12s - loss: 0.4579 - acc: 0.78 - ETA: 12s - loss: 0.4570 - acc: 0.78 - ETA: 12s - loss: 0.4573 - acc: 0.78 - ETA: 12s - loss: 0.4576 - acc: 0.78 - ETA: 12s - loss: 0.4580 - acc: 0.78 - ETA: 12s - loss: 0.4577 - acc: 0.78 - ETA: 12s - loss: 0.4570 - acc: 0.78 - ETA: 12s - loss: 0.4572 - acc: 0.78 - ETA: 12s - loss: 0.4571 - acc: 0.78 - ETA: 12s - loss: 0.4567 - acc: 0.78 - ETA: 12s - loss: 0.4567 - acc: 0.78 - ETA: 12s - loss: 0.4566 - acc: 0.78 - ETA: 11s - loss: 0.4565 - acc: 0.78 - ETA: 11s - loss: 0.4561 - acc: 0.78 - ETA: 11s - loss: 0.4563 - acc: 0.78 - ETA: 11s - loss: 0.4567 - acc: 0.78 - ETA: 11s - loss: 0.4569 - acc: 0.78 - ETA: 11s - loss: 0.4572 - acc: 0.78 - ETA: 11s - loss: 0.4573 - acc: 0.78 - ETA: 11s - loss: 0.4571 - acc: 0.78 - ETA: 11s - loss: 0.4570 - acc: 0.78 - ETA: 11s - loss: 0.4569 - acc: 0.78 - ETA: 11s - loss: 0.4570 - acc: 0.78 - ETA: 11s - loss: 0.4568 - acc: 0.78 - ETA: 11s - loss: 0.4568 - acc: 0.78 - ETA: 11s - loss: 0.4569 - acc: 0.78 - ETA: 11s - loss: 0.4567 - acc: 0.78 - ETA: 11s - loss: 0.4567 - acc: 0.78 - ETA: 11s - loss: 0.4568 - acc: 0.78 - ETA: 11s - loss: 0.4565 - acc: 0.78 - ETA: 10s - loss: 0.4566 - acc: 0.78 - ETA: 10s - loss: 0.4564 - acc: 0.78 - ETA: 10s - loss: 0.4565 - acc: 0.78 - ETA: 10s - loss: 0.4566 - acc: 0.78 - ETA: 10s - loss: 0.4563 - acc: 0.78 - ETA: 10s - loss: 0.4564 - acc: 0.78 - ETA: 10s - loss: 0.4561 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4558 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4560 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4558 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4561 - acc: 0.78 - ETA: 10s - loss: 0.4563 - acc: 0.78 - ETA: 10s - loss: 0.4562 - acc: 0.78 - ETA: 9s - loss: 0.4562 - acc: 0.7842 - ETA: 9s - loss: 0.4561 - acc: 0.784 - ETA: 9s - loss: 0.4559 - acc: 0.784 - ETA: 10s - loss: 0.4559 - acc: 0.78 - ETA: 10s - loss: 0.4562 - acc: 0.78 - ETA: 10s - loss: 0.4558 - acc: 0.78 - ETA: 10s - loss: 0.4558 - acc: 0.78 - ETA: 10s - loss: 0.4558 - acc: 0.78 - ETA: 9s - loss: 0.4559 - acc: 0.7845 - ETA: 9s - loss: 0.4557 - acc: 0.784 - ETA: 9s - loss: 0.4557 - acc: 0.784 - ETA: 9s - loss: 0.4556 - acc: 0.784 - ETA: 9s - loss: 0.4557 - acc: 0.784 - ETA: 9s - loss: 0.4555 - acc: 0.784 - ETA: 9s - loss: 0.4555 - acc: 0.784 - ETA: 9s - loss: 0.4556 - acc: 0.784 - ETA: 9s - loss: 0.4557 - acc: 0.784 - ETA: 9s - loss: 0.4556 - acc: 0.784 - ETA: 9s - loss: 0.4555 - acc: 0.785 - ETA: 9s - loss: 0.4555 - acc: 0.785 - ETA: 9s - loss: 0.4555 - acc: 0.785 - ETA: 9s - loss: 0.4554 - acc: 0.785 - ETA: 9s - loss: 0.4554 - acc: 0.785 - ETA: 9s - loss: 0.4553 - acc: 0.785 - ETA: 8s - loss: 0.4555 - acc: 0.784 - ETA: 8s - loss: 0.4555 - acc: 0.784 - ETA: 8s - loss: 0.4554 - acc: 0.784 - ETA: 8s - loss: 0.4555 - acc: 0.784 - ETA: 8s - loss: 0.4555 - acc: 0.784 - ETA: 8s - loss: 0.4556 - acc: 0.784 - ETA: 8s - loss: 0.4554 - acc: 0.785 - ETA: 8s - loss: 0.4554 - acc: 0.785 - ETA: 8s - loss: 0.4553 - acc: 0.785 - ETA: 8s - loss: 0.4554 - acc: 0.784 - ETA: 8s - loss: 0.4555 - acc: 0.784 - ETA: 8s - loss: 0.4556 - acc: 0.784 - ETA: 8s - loss: 0.4556 - acc: 0.784 - ETA: 8s - loss: 0.4554 - acc: 0.784 - ETA: 8s - loss: 0.4554 - acc: 0.785 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4556 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4556 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 7s - loss: 0.4554 - acc: 0.784 - ETA: 7s - loss: 0.4552 - acc: 0.785 - ETA: 7s - loss: 0.4552 - acc: 0.785 - ETA: 7s - loss: 0.4553 - acc: 0.784 - ETA: 7s - loss: 0.4554 - acc: 0.784 - ETA: 7s - loss: 0.4554 - acc: 0.784 - ETA: 7s - loss: 0.4554 - acc: 0.784 - ETA: 7s - loss: 0.4555 - acc: 0.784 - ETA: 6s - loss: 0.4553 - acc: 0.784 - ETA: 6s - loss: 0.4553 - acc: 0.784 - ETA: 6s - loss: 0.4552 - acc: 0.784 - ETA: 6s - loss: 0.4553 - acc: 0.784 - ETA: 6s - loss: 0.4552 - acc: 0.784 - ETA: 6s - loss: 0.4550 - acc: 0.785 - ETA: 6s - loss: 0.4551 - acc: 0.784 - ETA: 6s - loss: 0.4550 - acc: 0.785 - ETA: 6s - loss: 0.4549 - acc: 0.785 - ETA: 6s - loss: 0.4549 - acc: 0.785 - ETA: 6s - loss: 0.4550 - acc: 0.785 - ETA: 6s - loss: 0.4550 - acc: 0.785 - ETA: 6s - loss: 0.4550 - acc: 0.785 - ETA: 6s - loss: 0.4551 - acc: 0.785 - ETA: 6s - loss: 0.4551 - acc: 0.785 - ETA: 6s - loss: 0.4551 - acc: 0.785 - ETA: 6s - loss: 0.4551 - acc: 0.784 - ETA: 5s - loss: 0.4551 - acc: 0.785 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4552 - acc: 0.784 - ETA: 5s - loss: 0.4551 - acc: 0.784 - ETA: 5s - loss: 0.4551 - acc: 0.784 - ETA: 5s - loss: 0.4551 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4550 - acc: 0.784 - ETA: 5s - loss: 0.4549 - acc: 0.784 - ETA: 5s - loss: 0.4548 - acc: 0.784 - ETA: 5s - loss: 0.4548 - acc: 0.784 - ETA: 5s - loss: 0.4547 - acc: 0.784 - ETA: 4s - loss: 0.4546 - acc: 0.785 - ETA: 4s - loss: 0.4546 - acc: 0.785 - ETA: 4s - loss: 0.4544 - acc: 0.785 - ETA: 4s - loss: 0.4545 - acc: 0.785 - ETA: 4s - loss: 0.4544 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4542 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4544 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4544 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 4s - loss: 0.4544 - acc: 0.785 - ETA: 4s - loss: 0.4544 - acc: 0.785 - ETA: 4s - loss: 0.4543 - acc: 0.785 - ETA: 3s - loss: 0.4542 - acc: 0.785 - ETA: 3s - loss: 0.4542 - acc: 0.785 - ETA: 3s - loss: 0.4542 - acc: 0.785 - ETA: 3s - loss: 0.4541 - acc: 0.785 - ETA: 3s - loss: 0.4541 - acc: 0.785 - ETA: 3s - loss: 0.4540 - acc: 0.785 - ETA: 3s - loss: 0.4541 - acc: 0.785 - ETA: 3s - loss: 0.4541 - acc: 0.785 - ETA: 3s - loss: 0.4542 - acc: 0.785 - ETA: 3s - loss: 0.4542 - acc: 0.785 - ETA: 3s - loss: 0.4542 - acc: 0.785 - ETA: 3s - loss: 0.4541 - acc: 0.785 - ETA: 3s - loss: 0.4541 - acc: 0.785 - ETA: 3s - loss: 0.4540 - acc: 0.785 - ETA: 3s - loss: 0.4539 - acc: 0.785 - ETA: 3s - loss: 0.4539 - acc: 0.785 - ETA: 3s - loss: 0.4539 - acc: 0.785 - ETA: 3s - loss: 0.4539 - acc: 0.785 - ETA: 3s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4540 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.7856"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739/2745 [============================>.] - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4538 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4539 - acc: 0.785 - ETA: 2s - loss: 0.4538 - acc: 0.785 - ETA: 2s - loss: 0.4538 - acc: 0.785 - ETA: 2s - loss: 0.4537 - acc: 0.785 - ETA: 2s - loss: 0.4538 - acc: 0.785 - ETA: 2s - loss: 0.4537 - acc: 0.785 - ETA: 2s - loss: 0.4536 - acc: 0.785 - ETA: 1s - loss: 0.4536 - acc: 0.785 - ETA: 1s - loss: 0.4535 - acc: 0.785 - ETA: 1s - loss: 0.4535 - acc: 0.785 - ETA: 1s - loss: 0.4535 - acc: 0.785 - ETA: 1s - loss: 0.4534 - acc: 0.785 - ETA: 1s - loss: 0.4535 - acc: 0.785 - ETA: 1s - loss: 0.4535 - acc: 0.785 - ETA: 1s - loss: 0.4535 - acc: 0.785 - ETA: 1s - loss: 0.4534 - acc: 0.785 - ETA: 1s - loss: 0.4533 - acc: 0.785 - ETA: 1s - loss: 0.4533 - acc: 0.786 - ETA: 1s - loss: 0.4533 - acc: 0.786 - ETA: 1s - loss: 0.4534 - acc: 0.785 - ETA: 1s - loss: 0.4533 - acc: 0.786 - ETA: 1s - loss: 0.4533 - acc: 0.786 - ETA: 1s - loss: 0.4533 - acc: 0.786 - ETA: 1s - loss: 0.4532 - acc: 0.786 - ETA: 1s - loss: 0.4532 - acc: 0.786 - ETA: 1s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4531 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4533 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4532 - acc: 0.786 - ETA: 0s - loss: 0.4531 - acc: 0.786 - ETA: 0s - loss: 0.4530 - acc: 0.786 - ETA: 0s - loss: 0.4530 - acc: 0.786 - ETA: 0s - loss: 0.4530 - acc: 0.7864\n",
      "Epoch 00002: val_loss improved from 0.47645 to 0.45995, saving model to C:\\Users\\remoteuser\\tatk\\resources\\logs\\checkpoints\n",
      "2745/2745 [==============================] - 17s 6ms/step - loss: 0.4531 - acc: 0.7864 - val_loss: 0.4599 - val_acc: 0.7984\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2142/2745 [======================>.......] - ETA: 13s - loss: 0.4675 - acc: 0.78 - ETA: 13s - loss: 0.4540 - acc: 0.79 - ETA: 13s - loss: 0.4514 - acc: 0.79 - ETA: 13s - loss: 0.4536 - acc: 0.78 - ETA: 13s - loss: 0.4489 - acc: 0.78 - ETA: 13s - loss: 0.4498 - acc: 0.78 - ETA: 13s - loss: 0.4516 - acc: 0.78 - ETA: 13s - loss: 0.4490 - acc: 0.78 - ETA: 13s - loss: 0.4490 - acc: 0.78 - ETA: 13s - loss: 0.4483 - acc: 0.78 - ETA: 13s - loss: 0.4470 - acc: 0.78 - ETA: 13s - loss: 0.4480 - acc: 0.78 - ETA: 13s - loss: 0.4464 - acc: 0.78 - ETA: 13s - loss: 0.4457 - acc: 0.79 - ETA: 13s - loss: 0.4467 - acc: 0.78 - ETA: 13s - loss: 0.4468 - acc: 0.78 - ETA: 13s - loss: 0.4471 - acc: 0.78 - ETA: 13s - loss: 0.4471 - acc: 0.78 - ETA: 13s - loss: 0.4464 - acc: 0.78 - ETA: 13s - loss: 0.4463 - acc: 0.78 - ETA: 13s - loss: 0.4454 - acc: 0.79 - ETA: 13s - loss: 0.4455 - acc: 0.79 - ETA: 13s - loss: 0.4458 - acc: 0.79 - ETA: 13s - loss: 0.4458 - acc: 0.79 - ETA: 13s - loss: 0.4470 - acc: 0.79 - ETA: 13s - loss: 0.4464 - acc: 0.79 - ETA: 13s - loss: 0.4456 - acc: 0.79 - ETA: 13s - loss: 0.4457 - acc: 0.79 - ETA: 13s - loss: 0.4460 - acc: 0.79 - ETA: 13s - loss: 0.4460 - acc: 0.79 - ETA: 13s - loss: 0.4457 - acc: 0.79 - ETA: 13s - loss: 0.4453 - acc: 0.79 - ETA: 13s - loss: 0.4453 - acc: 0.79 - ETA: 13s - loss: 0.4451 - acc: 0.79 - ETA: 12s - loss: 0.4450 - acc: 0.79 - ETA: 12s - loss: 0.4451 - acc: 0.79 - ETA: 12s - loss: 0.4449 - acc: 0.79 - ETA: 12s - loss: 0.4448 - acc: 0.79 - ETA: 12s - loss: 0.4446 - acc: 0.79 - ETA: 12s - loss: 0.4441 - acc: 0.79 - ETA: 12s - loss: 0.4442 - acc: 0.79 - ETA: 12s - loss: 0.4443 - acc: 0.79 - ETA: 12s - loss: 0.4443 - acc: 0.79 - ETA: 12s - loss: 0.4448 - acc: 0.79 - ETA: 12s - loss: 0.4449 - acc: 0.79 - ETA: 12s - loss: 0.4450 - acc: 0.79 - ETA: 12s - loss: 0.4446 - acc: 0.79 - ETA: 12s - loss: 0.4446 - acc: 0.79 - ETA: 12s - loss: 0.4446 - acc: 0.79 - ETA: 12s - loss: 0.4444 - acc: 0.79 - ETA: 12s - loss: 0.4444 - acc: 0.79 - ETA: 12s - loss: 0.4445 - acc: 0.79 - ETA: 12s - loss: 0.4445 - acc: 0.79 - ETA: 12s - loss: 0.4444 - acc: 0.79 - ETA: 12s - loss: 0.4441 - acc: 0.79 - ETA: 12s - loss: 0.4442 - acc: 0.79 - ETA: 12s - loss: 0.4444 - acc: 0.79 - ETA: 12s - loss: 0.4444 - acc: 0.79 - ETA: 12s - loss: 0.4443 - acc: 0.79 - ETA: 12s - loss: 0.4441 - acc: 0.79 - ETA: 11s - loss: 0.4441 - acc: 0.79 - ETA: 11s - loss: 0.4446 - acc: 0.79 - ETA: 11s - loss: 0.4448 - acc: 0.79 - ETA: 11s - loss: 0.4447 - acc: 0.79 - ETA: 11s - loss: 0.4449 - acc: 0.79 - ETA: 11s - loss: 0.4448 - acc: 0.79 - ETA: 11s - loss: 0.4452 - acc: 0.79 - ETA: 11s - loss: 0.4452 - acc: 0.79 - ETA: 11s - loss: 0.4452 - acc: 0.79 - ETA: 11s - loss: 0.4450 - acc: 0.79 - ETA: 11s - loss: 0.4449 - acc: 0.79 - ETA: 11s - loss: 0.4449 - acc: 0.79 - ETA: 11s - loss: 0.4449 - acc: 0.79 - ETA: 11s - loss: 0.4448 - acc: 0.79 - ETA: 10s - loss: 0.4446 - acc: 0.79 - ETA: 10s - loss: 0.4445 - acc: 0.79 - ETA: 10s - loss: 0.4445 - acc: 0.79 - ETA: 10s - loss: 0.4446 - acc: 0.79 - ETA: 10s - loss: 0.4448 - acc: 0.79 - ETA: 10s - loss: 0.4448 - acc: 0.79 - ETA: 10s - loss: 0.4448 - acc: 0.79 - ETA: 10s - loss: 0.4448 - acc: 0.79 - ETA: 10s - loss: 0.4450 - acc: 0.79 - ETA: 10s - loss: 0.4451 - acc: 0.79 - ETA: 10s - loss: 0.4453 - acc: 0.79 - ETA: 10s - loss: 0.4455 - acc: 0.79 - ETA: 10s - loss: 0.4454 - acc: 0.79 - ETA: 10s - loss: 0.4454 - acc: 0.79 - ETA: 10s - loss: 0.4454 - acc: 0.79 - ETA: 10s - loss: 0.4451 - acc: 0.79 - ETA: 9s - loss: 0.4451 - acc: 0.7918 - ETA: 9s - loss: 0.4451 - acc: 0.791 - ETA: 9s - loss: 0.4450 - acc: 0.791 - ETA: 9s - loss: 0.4449 - acc: 0.792 - ETA: 9s - loss: 0.4448 - acc: 0.792 - ETA: 9s - loss: 0.4447 - acc: 0.792 - ETA: 9s - loss: 0.4448 - acc: 0.792 - ETA: 9s - loss: 0.4448 - acc: 0.792 - ETA: 9s - loss: 0.4448 - acc: 0.791 - ETA: 9s - loss: 0.4449 - acc: 0.791 - ETA: 9s - loss: 0.4447 - acc: 0.791 - ETA: 9s - loss: 0.4447 - acc: 0.791 - ETA: 9s - loss: 0.4447 - acc: 0.791 - ETA: 9s - loss: 0.4447 - acc: 0.791 - ETA: 9s - loss: 0.4448 - acc: 0.791 - ETA: 9s - loss: 0.4448 - acc: 0.791 - ETA: 9s - loss: 0.4447 - acc: 0.791 - ETA: 8s - loss: 0.4448 - acc: 0.791 - ETA: 8s - loss: 0.4448 - acc: 0.791 - ETA: 8s - loss: 0.4448 - acc: 0.791 - ETA: 8s - loss: 0.4447 - acc: 0.791 - ETA: 8s - loss: 0.4446 - acc: 0.791 - ETA: 8s - loss: 0.4444 - acc: 0.791 - ETA: 8s - loss: 0.4444 - acc: 0.791 - ETA: 8s - loss: 0.4446 - acc: 0.791 - ETA: 8s - loss: 0.4445 - acc: 0.791 - ETA: 8s - loss: 0.4446 - acc: 0.791 - ETA: 8s - loss: 0.4445 - acc: 0.791 - ETA: 8s - loss: 0.4445 - acc: 0.791 - ETA: 8s - loss: 0.4446 - acc: 0.791 - ETA: 8s - loss: 0.4445 - acc: 0.791 - ETA: 8s - loss: 0.4446 - acc: 0.791 - ETA: 8s - loss: 0.4447 - acc: 0.791 - ETA: 8s - loss: 0.4449 - acc: 0.791 - ETA: 8s - loss: 0.4450 - acc: 0.791 - ETA: 8s - loss: 0.4449 - acc: 0.791 - ETA: 8s - loss: 0.4449 - acc: 0.791 - ETA: 7s - loss: 0.4448 - acc: 0.791 - ETA: 7s - loss: 0.4448 - acc: 0.791 - ETA: 7s - loss: 0.4450 - acc: 0.791 - ETA: 7s - loss: 0.4449 - acc: 0.791 - ETA: 7s - loss: 0.4449 - acc: 0.791 - ETA: 7s - loss: 0.4447 - acc: 0.791 - ETA: 7s - loss: 0.4447 - acc: 0.791 - ETA: 7s - loss: 0.4449 - acc: 0.791 - ETA: 7s - loss: 0.4450 - acc: 0.791 - ETA: 7s - loss: 0.4449 - acc: 0.791 - ETA: 7s - loss: 0.4450 - acc: 0.791 - ETA: 7s - loss: 0.4450 - acc: 0.791 - ETA: 7s - loss: 0.4448 - acc: 0.791 - ETA: 7s - loss: 0.4448 - acc: 0.791 - ETA: 7s - loss: 0.4448 - acc: 0.791 - ETA: 7s - loss: 0.4448 - acc: 0.791 - ETA: 7s - loss: 0.4447 - acc: 0.791 - ETA: 7s - loss: 0.4449 - acc: 0.791 - ETA: 7s - loss: 0.4450 - acc: 0.791 - ETA: 6s - loss: 0.4449 - acc: 0.791 - ETA: 6s - loss: 0.4448 - acc: 0.791 - ETA: 6s - loss: 0.4449 - acc: 0.791 - ETA: 6s - loss: 0.4450 - acc: 0.791 - ETA: 6s - loss: 0.4451 - acc: 0.791 - ETA: 6s - loss: 0.4451 - acc: 0.791 - ETA: 6s - loss: 0.4451 - acc: 0.791 - ETA: 6s - loss: 0.4451 - acc: 0.791 - ETA: 6s - loss: 0.4452 - acc: 0.791 - ETA: 6s - loss: 0.4452 - acc: 0.791 - ETA: 6s - loss: 0.4451 - acc: 0.791 - ETA: 6s - loss: 0.4450 - acc: 0.791 - ETA: 6s - loss: 0.4450 - acc: 0.791 - ETA: 6s - loss: 0.4450 - acc: 0.791 - ETA: 6s - loss: 0.4450 - acc: 0.791 - ETA: 6s - loss: 0.4449 - acc: 0.791 - ETA: 6s - loss: 0.4449 - acc: 0.791 - ETA: 6s - loss: 0.4449 - acc: 0.791 - ETA: 6s - loss: 0.4451 - acc: 0.791 - ETA: 5s - loss: 0.4452 - acc: 0.791 - ETA: 5s - loss: 0.4451 - acc: 0.791 - ETA: 5s - loss: 0.4450 - acc: 0.791 - ETA: 5s - loss: 0.4451 - acc: 0.791 - ETA: 5s - loss: 0.4451 - acc: 0.791 - ETA: 5s - loss: 0.4450 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4450 - acc: 0.790 - ETA: 5s - loss: 0.4450 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4451 - acc: 0.790 - ETA: 5s - loss: 0.4450 - acc: 0.790 - ETA: 4s - loss: 0.4450 - acc: 0.790 - ETA: 4s - loss: 0.4450 - acc: 0.790 - ETA: 4s - loss: 0.4449 - acc: 0.790 - ETA: 4s - loss: 0.4448 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.791 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4447 - acc: 0.790 - ETA: 4s - loss: 0.4448 - acc: 0.790 - ETA: 4s - loss: 0.4449 - acc: 0.790 - ETA: 4s - loss: 0.4449 - acc: 0.790 - ETA: 4s - loss: 0.4449 - acc: 0.790 - ETA: 3s - loss: 0.4449 - acc: 0.790 - ETA: 3s - loss: 0.4450 - acc: 0.790 - ETA: 3s - loss: 0.4450 - acc: 0.790 - ETA: 3s - loss: 0.4449 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.790 - ETA: 3s - loss: 0.4447 - acc: 0.790 - ETA: 3s - loss: 0.4447 - acc: 0.790 - ETA: 3s - loss: 0.4447 - acc: 0.790 - ETA: 3s - loss: 0.4447 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.790 - ETA: 3s - loss: 0.4448 - acc: 0.79092740/2745 [============================>.] - ETA: 3s - loss: 0.4446 - acc: 0.790 - ETA: 3s - loss: 0.4446 - acc: 0.791 - ETA: 3s - loss: 0.4445 - acc: 0.791 - ETA: 3s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4444 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.790 - ETA: 2s - loss: 0.4446 - acc: 0.790 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4445 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4446 - acc: 0.791 - ETA: 2s - loss: 0.4444 - acc: 0.791 - ETA: 1s - loss: 0.4445 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4445 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 1s - loss: 0.4446 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.790 - ETA: 0s - loss: 0.4447 - acc: 0.790 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.790 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.790 - ETA: 0s - loss: 0.4447 - acc: 0.790 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4447 - acc: 0.791 - ETA: 0s - loss: 0.4446 - acc: 0.791 - ETA: 0s - loss: 0.4446 - acc: 0.791 - ETA: 0s - loss: 0.4446 - acc: 0.791 - ETA: 0s - loss: 0.4446 - acc: 0.791 - ETA: 0s - loss: 0.4446 - acc: 0.7911\n",
      "Epoch 00003: val_loss did not improve\n",
      "2745/2745 [==============================] - 17s 6ms/step - loss: 0.4446 - acc: 0.7911 - val_loss: 0.4613 - val_acc: 0.8007\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170/2745 [======================>.......] - ETA: 13s - loss: 0.4385 - acc: 0.80 - ETA: 14s - loss: 0.4428 - acc: 0.79 - ETA: 14s - loss: 0.4392 - acc: 0.79 - ETA: 13s - loss: 0.4352 - acc: 0.79 - ETA: 13s - loss: 0.4347 - acc: 0.79 - ETA: 13s - loss: 0.4322 - acc: 0.79 - ETA: 13s - loss: 0.4367 - acc: 0.79 - ETA: 13s - loss: 0.4350 - acc: 0.79 - ETA: 13s - loss: 0.4350 - acc: 0.79 - ETA: 13s - loss: 0.4347 - acc: 0.79 - ETA: 13s - loss: 0.4346 - acc: 0.79 - ETA: 13s - loss: 0.4342 - acc: 0.79 - ETA: 13s - loss: 0.4350 - acc: 0.79 - ETA: 13s - loss: 0.4368 - acc: 0.79 - ETA: 13s - loss: 0.4359 - acc: 0.79 - ETA: 13s - loss: 0.4360 - acc: 0.79 - ETA: 13s - loss: 0.4371 - acc: 0.79 - ETA: 13s - loss: 0.4366 - acc: 0.79 - ETA: 13s - loss: 0.4370 - acc: 0.79 - ETA: 13s - loss: 0.4383 - acc: 0.79 - ETA: 13s - loss: 0.4381 - acc: 0.79 - ETA: 13s - loss: 0.4384 - acc: 0.79 - ETA: 13s - loss: 0.4384 - acc: 0.79 - ETA: 13s - loss: 0.4390 - acc: 0.79 - ETA: 13s - loss: 0.4394 - acc: 0.79 - ETA: 13s - loss: 0.4394 - acc: 0.79 - ETA: 13s - loss: 0.4394 - acc: 0.79 - ETA: 12s - loss: 0.4389 - acc: 0.79 - ETA: 12s - loss: 0.4385 - acc: 0.79 - ETA: 12s - loss: 0.4380 - acc: 0.79 - ETA: 12s - loss: 0.4375 - acc: 0.79 - ETA: 12s - loss: 0.4369 - acc: 0.79 - ETA: 12s - loss: 0.4374 - acc: 0.79 - ETA: 12s - loss: 0.4374 - acc: 0.79 - ETA: 12s - loss: 0.4372 - acc: 0.79 - ETA: 12s - loss: 0.4377 - acc: 0.79 - ETA: 12s - loss: 0.4380 - acc: 0.79 - ETA: 12s - loss: 0.4381 - acc: 0.79 - ETA: 12s - loss: 0.4376 - acc: 0.79 - ETA: 12s - loss: 0.4375 - acc: 0.79 - ETA: 12s - loss: 0.4374 - acc: 0.79 - ETA: 12s - loss: 0.4377 - acc: 0.79 - ETA: 12s - loss: 0.4376 - acc: 0.79 - ETA: 12s - loss: 0.4377 - acc: 0.79 - ETA: 12s - loss: 0.4373 - acc: 0.79 - ETA: 12s - loss: 0.4370 - acc: 0.79 - ETA: 12s - loss: 0.4368 - acc: 0.79 - ETA: 12s - loss: 0.4370 - acc: 0.79 - ETA: 11s - loss: 0.4371 - acc: 0.79 - ETA: 11s - loss: 0.4367 - acc: 0.79 - ETA: 11s - loss: 0.4369 - acc: 0.79 - ETA: 11s - loss: 0.4367 - acc: 0.79 - ETA: 11s - loss: 0.4367 - acc: 0.79 - ETA: 11s - loss: 0.4366 - acc: 0.79 - ETA: 11s - loss: 0.4362 - acc: 0.79 - ETA: 11s - loss: 0.4365 - acc: 0.79 - ETA: 11s - loss: 0.4366 - acc: 0.79 - ETA: 11s - loss: 0.4366 - acc: 0.79 - ETA: 11s - loss: 0.4368 - acc: 0.79 - ETA: 11s - loss: 0.4366 - acc: 0.79 - ETA: 11s - loss: 0.4370 - acc: 0.79 - ETA: 11s - loss: 0.4370 - acc: 0.79 - ETA: 11s - loss: 0.4371 - acc: 0.79 - ETA: 11s - loss: 0.4369 - acc: 0.79 - ETA: 11s - loss: 0.4371 - acc: 0.79 - ETA: 11s - loss: 0.4371 - acc: 0.79 - ETA: 11s - loss: 0.4373 - acc: 0.79 - ETA: 11s - loss: 0.4371 - acc: 0.79 - ETA: 10s - loss: 0.4371 - acc: 0.79 - ETA: 10s - loss: 0.4370 - acc: 0.79 - ETA: 10s - loss: 0.4370 - acc: 0.79 - ETA: 10s - loss: 0.4373 - acc: 0.79 - ETA: 10s - loss: 0.4375 - acc: 0.79 - ETA: 10s - loss: 0.4375 - acc: 0.79 - ETA: 10s - loss: 0.4374 - acc: 0.79 - ETA: 10s - loss: 0.4375 - acc: 0.79 - ETA: 10s - loss: 0.4377 - acc: 0.79 - ETA: 10s - loss: 0.4374 - acc: 0.79 - ETA: 10s - loss: 0.4377 - acc: 0.79 - ETA: 10s - loss: 0.4379 - acc: 0.79 - ETA: 10s - loss: 0.4381 - acc: 0.79 - ETA: 10s - loss: 0.4381 - acc: 0.79 - ETA: 10s - loss: 0.4382 - acc: 0.79 - ETA: 10s - loss: 0.4381 - acc: 0.79 - ETA: 10s - loss: 0.4381 - acc: 0.79 - ETA: 10s - loss: 0.4382 - acc: 0.79 - ETA: 9s - loss: 0.4381 - acc: 0.7948 - ETA: 9s - loss: 0.4382 - acc: 0.794 - ETA: 9s - loss: 0.4383 - acc: 0.794 - ETA: 9s - loss: 0.4382 - acc: 0.794 - ETA: 9s - loss: 0.4384 - acc: 0.794 - ETA: 9s - loss: 0.4383 - acc: 0.794 - ETA: 9s - loss: 0.4384 - acc: 0.794 - ETA: 9s - loss: 0.4386 - acc: 0.794 - ETA: 9s - loss: 0.4387 - acc: 0.794 - ETA: 9s - loss: 0.4389 - acc: 0.794 - ETA: 9s - loss: 0.4389 - acc: 0.794 - ETA: 9s - loss: 0.4389 - acc: 0.794 - ETA: 9s - loss: 0.4389 - acc: 0.794 - ETA: 9s - loss: 0.4388 - acc: 0.794 - ETA: 9s - loss: 0.4389 - acc: 0.794 - ETA: 9s - loss: 0.4390 - acc: 0.794 - ETA: 9s - loss: 0.4389 - acc: 0.794 - ETA: 9s - loss: 0.4388 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4388 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4389 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4390 - acc: 0.794 - ETA: 8s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4392 - acc: 0.794 - ETA: 7s - loss: 0.4392 - acc: 0.794 - ETA: 7s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4391 - acc: 0.794 - ETA: 7s - loss: 0.4390 - acc: 0.794 - ETA: 7s - loss: 0.4389 - acc: 0.794 - ETA: 7s - loss: 0.4389 - acc: 0.794 - ETA: 6s - loss: 0.4390 - acc: 0.794 - ETA: 6s - loss: 0.4389 - acc: 0.794 - ETA: 6s - loss: 0.4389 - acc: 0.794 - ETA: 6s - loss: 0.4390 - acc: 0.794 - ETA: 6s - loss: 0.4390 - acc: 0.794 - ETA: 6s - loss: 0.4391 - acc: 0.794 - ETA: 6s - loss: 0.4391 - acc: 0.794 - ETA: 6s - loss: 0.4391 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4392 - acc: 0.794 - ETA: 6s - loss: 0.4392 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 6s - loss: 0.4394 - acc: 0.794 - ETA: 6s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4392 - acc: 0.794 - ETA: 5s - loss: 0.4393 - acc: 0.794 - ETA: 5s - loss: 0.4394 - acc: 0.794 - ETA: 5s - loss: 0.4394 - acc: 0.794 - ETA: 4s - loss: 0.4395 - acc: 0.794 - ETA: 4s - loss: 0.4395 - acc: 0.794 - ETA: 4s - loss: 0.4396 - acc: 0.794 - ETA: 4s - loss: 0.4395 - acc: 0.794 - ETA: 4s - loss: 0.4394 - acc: 0.794 - ETA: 4s - loss: 0.4394 - acc: 0.794 - ETA: 4s - loss: 0.4393 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 4s - loss: 0.4393 - acc: 0.794 - ETA: 4s - loss: 0.4393 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 4s - loss: 0.4393 - acc: 0.794 - ETA: 4s - loss: 0.4393 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 4s - loss: 0.4392 - acc: 0.794 - ETA: 3s - loss: 0.4392 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4394 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4394 - acc: 0.794 - ETA: 3s - loss: 0.4393 - acc: 0.794 - ETA: 3s - loss: 0.4394 - acc: 0.794 - ETA: 3s - loss: 0.4394 - acc: 0.794 - ETA: 3s - loss: 0.4396 - acc: 0.794 - ETA: 3s - loss: 0.4396 - acc: 0.794 - ETA: 3s - loss: 0.4396 - acc: 0.794 - ETA: 3s - loss: 0.4397 - acc: 0.794 - ETA: 3s - loss: 0.4398 - acc: 0.7940"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2741/2745 [============================>.] - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4398 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 2s - loss: 0.4400 - acc: 0.794 - ETA: 2s - loss: 0.4400 - acc: 0.794 - ETA: 2s - loss: 0.4400 - acc: 0.794 - ETA: 2s - loss: 0.4400 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 2s - loss: 0.4399 - acc: 0.794 - ETA: 1s - loss: 0.4399 - acc: 0.794 - ETA: 1s - loss: 0.4399 - acc: 0.794 - ETA: 1s - loss: 0.4399 - acc: 0.794 - ETA: 1s - loss: 0.4399 - acc: 0.794 - ETA: 1s - loss: 0.4399 - acc: 0.794 - ETA: 1s - loss: 0.4398 - acc: 0.794 - ETA: 1s - loss: 0.4398 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 1s - loss: 0.4398 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 1s - loss: 0.4396 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 1s - loss: 0.4398 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 1s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4396 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4398 - acc: 0.794 - ETA: 0s - loss: 0.4399 - acc: 0.794 - ETA: 0s - loss: 0.4399 - acc: 0.794 - ETA: 0s - loss: 0.4399 - acc: 0.794 - ETA: 0s - loss: 0.4400 - acc: 0.794 - ETA: 0s - loss: 0.4400 - acc: 0.794 - ETA: 0s - loss: 0.4400 - acc: 0.794 - ETA: 0s - loss: 0.4399 - acc: 0.794 - ETA: 0s - loss: 0.4398 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4398 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4397 - acc: 0.794 - ETA: 0s - loss: 0.4398 - acc: 0.7942\n",
      "Epoch 00004: val_loss did not improve\n",
      "2745/2745 [==============================] - 17s 6ms/step - loss: 0.4398 - acc: 0.7942 - val_loss: 0.4604 - val_acc: 0.8049\n",
      "KerasEmbeddingTextClassifierLearner::tatk_fit ==> end \t Time taken: 7.07 mins\n",
      "Time taken: 7.64 mins\n",
      "KerasEmbeddingTextClassifier::fit ==> end\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasEmbeddingTextClassifier(binary_format=False, callbacks=True,\n",
       "               class_type='single-label', cuda_devices='0',\n",
       "               embedding_file_path='C:\\\\\\\\Users\\\\\\\\remoteuser\\\\\\\\Desktop\\\\\\\\Data\\\\\\\\Sentiment140_Classification\\\\w2vec.txt',\n",
       "               input_col='tweets', label_cols=['labels'], limit=None,\n",
       "               log_dir='C:\\\\Users\\\\remoteuser\\\\tatk\\\\resources\\\\logs',\n",
       "               model_type='CNN', n_labels=None, regex=None,\n",
       "               trainable_embedding=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_text_classifier.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextModel::save ==> start\n",
      "TatkPipeline::save ==> start\n",
      "Time taken: 0.03 mins\n",
      "TatkPipeline::save ==> end\n",
      "Time taken: 0.17 mins\n",
      "BaseTextModel::save ==> end\n"
     ]
    }
   ],
   "source": [
    "keras_text_classifier.save(keras_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and evaluate performance on a set of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseTextModel::load ==> start\n",
      "TatkPipeline::load ==> start\n",
      "Word '<UNK>' is already in vocabulary.\n",
      "Word '<<ZERO>>' is already in vocabulary.\n",
      "Word2VecVectorizer: Word2Vec model loaded from C:\\\\Users\\\\remoteuser\\\\Desktop\\\\Data\\\\Sentiment140_Classification\\sk_model.zip 2018-05-30 23.58.51\\sk_model\\pipeline\\vectorizer\\embedding_table.txt\n",
      "Time taken: 0.09 mins\n",
      "TatkPipeline::load ==> end\n",
      "Time taken: 0.11 mins\n",
      "BaseTextModel::load ==> end\n"
     ]
    }
   ],
   "source": [
    "keras_text_classifier_reloaded = KerasTextClassifier.load(keras_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = valid[['tweets','labels']]\n",
    "type(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasEmbeddingTextClassifier ::predict ==> start\n",
      "NltkPreprocessor::tatk_transform ==> start\n",
      "NltkPreprocessor::tatk_transform ==> end \t Time taken: 0.14 mins\n",
      "Word2VecVectorizer::tatk_transform ==> start\n",
      "Word2VecVectorizer::tatk_transform ==> end \t Time taken: 0.12 mins\n",
      "KerasEmbeddingTextClassifierLearner::tatk_predict_proba ==> start\n",
      "KerasEmbeddingTextClassifierLearner::tatk_predict_proba ==> end \t Time taken: 0.33 mins\n",
      "KerasEmbeddingTextClassifierLearner::tatk_predict ==> start\n",
      "KerasEmbeddingTextClassifierLearner::tatk_predict ==> end \t Time taken: 0.33 mins\n",
      "Time taken: 0.92 mins\n",
      "KerasEmbeddingTextClassifier ::predict ==> end\n",
      "Order of Labels in predicted probabilities saved to attribute label_order of the class object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518808</th>\n",
       "      <td>AT kt_93 hehe i know</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.32005498, 0.679945]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166749</th>\n",
       "      <td>AT katiecorless bollocks . i would of loved t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.43475437, 0.5652456]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840126</th>\n",
       "      <td>AT porceleindoll come to wa and i'll help you...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.14480193, 0.8551981]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510697</th>\n",
       "      <td>AT stephizzle aw ino miss . dw . ull be fine ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.50850034, 0.4914996]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159753</th>\n",
       "      <td>AT getloaded . just another work day for poor...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.80050087, 0.19949912]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets  labels  \\\n",
       "518808                               AT kt_93 hehe i know       1   \n",
       "166749   AT katiecorless bollocks . i would of loved t...       0   \n",
       "840126   AT porceleindoll come to wa and i'll help you...       1   \n",
       "510697   AT stephizzle aw ino miss . dw . ull be fine ...       1   \n",
       "159753   AT getloaded . just another work day for poor...       0   \n",
       "\n",
       "                   probabilities  prediction  \n",
       "518808    [0.32005498, 0.679945]           1  \n",
       "166749   [0.43475437, 0.5652456]           1  \n",
       "840126   [0.14480193, 0.8551981]           1  \n",
       "510697   [0.50850034, 0.4914996]           0  \n",
       "159753  [0.80050087, 0.19949912]           0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = keras_text_classifier_reloaded.predict(valid)\n",
    "\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier ::evaluate ==> start\n",
      "Time taken: 0.02 mins\n",
      "TextClassifier ::evaluate ==> end\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a443d74e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8034183853635513"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations = text_classifier_reloaded.evaluate(valid)\n",
    "evaluations.plot_confusion_matrix(normalize=False,\n",
    "                                title='Confusion matrix, without normalization', \n",
    "                                print_confusion_matrix=False,\n",
    "                                figsize=(6,6),\n",
    "                                colors=None)\n",
    "evaluations.get_metrics('micro_avg_accuracy')\n",
    "evaluations.get_metrics('macro_avg_accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
